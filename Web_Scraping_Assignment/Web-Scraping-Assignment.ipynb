{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fcc9974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae737c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7d13745",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97a7afb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea25a1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4500d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99ff9d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bbea22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "480f0f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  0   \\\n",
      "0                                   Reward is enough   \n",
      "1  David Silver, Satinder Singh, Doina Precup, Ri...   \n",
      "2                                       October 2021   \n",
      "\n",
      "                                                  1   \\\n",
      "0  Explanation in artificial intelligence: Insigh...   \n",
      "1                                         Tim Miller   \n",
      "2                                      February 2019   \n",
      "\n",
      "                                       2   \\\n",
      "0  Creativity and artificial intelligence   \n",
      "1                       Margaret A. Boden   \n",
      "2                             August 1998   \n",
      "\n",
      "                                                  3   \\\n",
      "0  Conflict-based search for optimal multi-agent ...   \n",
      "1  Guni Sharon, Roni Stern, Ariel Felner, Nathan ...   \n",
      "2                                      February 2015   \n",
      "\n",
      "                                                  4   \\\n",
      "0  Knowledge graphs as tools for explainable mach...   \n",
      "1                     Ilaria Tiddi, Stefan Schlobach   \n",
      "2                                       January 2022   \n",
      "\n",
      "                                                  5   \\\n",
      "0  Law and logic: A review from an argumentation ...   \n",
      "1                     Henry Prakken, Giovanni Sartor   \n",
      "2                                       October 2015   \n",
      "\n",
      "                                                  6   \\\n",
      "0  Between MDPs and semi-MDPs: A framework for te...   \n",
      "1    Richard S. Sutton, Doina Precup, Satinder Singh   \n",
      "2                                        August 1999   \n",
      "\n",
      "                                                  7   \\\n",
      "0  Explaining individual predictions when feature...   \n",
      "1          Kjersti Aas, Martin Jullum, Anders Løland   \n",
      "2                                     September 2021   \n",
      "\n",
      "                                              8   \\\n",
      "0  Multiple object tracking: A literature review   \n",
      "1           Wenhan Luo, Junliang Xing and 4 more   \n",
      "2                                     April 2021   \n",
      "\n",
      "                                                  9   ...  \\\n",
      "0  A survey of inverse reinforcement learning: Ch...  ...   \n",
      "1                      Saurabh Arora, Prashant Doshi  ...   \n",
      "2                                        August 2021  ...   \n",
      "\n",
      "                                                  14  \\\n",
      "0  Explaining black-box classifiers using post-ho...   \n",
      "1  Eoin M. Kenny, Courtney Ford, Molly Quinn, Mar...   \n",
      "2                                           May 2021   \n",
      "\n",
      "                                                  15  \\\n",
      "0  The Hanabi challenge: A new frontier for AI re...   \n",
      "1          Nolan Bard, Jakob N. Foerster and 13 more   \n",
      "2                                         March 2020   \n",
      "\n",
      "                                      16  \\\n",
      "0  Wrappers for feature subset selection   \n",
      "1             Ron Kohavi, George H. John   \n",
      "2                          December 1997   \n",
      "\n",
      "                                                  17  \\\n",
      "0  Artificial cognition for social human–robot in...   \n",
      "1      Séverin Lemaignan, Mathieu Warnier and 3 more   \n",
      "2                                          June 2017   \n",
      "\n",
      "                                                  18  \\\n",
      "0  A review of possible effects of cognitive bias...   \n",
      "1    Tomáš Kliegr, Štěpán Bahník, Johannes Fürnkranz   \n",
      "2                                          June 2021   \n",
      "\n",
      "                                                  19  \\\n",
      "0  The multifaceted impact of Ada Lovelace in the...   \n",
      "1                             Luigia Carlucci Aiello   \n",
      "2                                          June 2016   \n",
      "\n",
      "                                                  20  \\\n",
      "0  Robot ethics: Mapping the issues for a mechani...   \n",
      "1             Patrick Lin, Keith Abney, George Bekey   \n",
      "2                                         April 2011   \n",
      "\n",
      "                                               21  \\\n",
      "0       Reward (Mis)design for autonomous driving   \n",
      "1  W. Bradley Knox, Alessandro Allievi and 3 more   \n",
      "2                                      March 2023   \n",
      "\n",
      "                                                  22  \\\n",
      "0  Planning and acting in partially observable st...   \n",
      "1  Leslie Pack Kaelbling, Michael L. Littman, Ant...   \n",
      "2                                           May 1998   \n",
      "\n",
      "                                                  23  \n",
      "0  What do we want from Explainable Artificial In...  \n",
      "1             Markus Langer, Daniel Oster and 6 more  \n",
      "2                                          July 2021  \n",
      "\n",
      "[3 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "#Write a python program to scrape the details of most downloaded articles from AI in last 90 \n",
    "#days.https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles \n",
    "#Scrape below mentioned details and make data frame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url='https://www.journals.elsevier.com/artificial-intelligence/most-downloaded-articles'\n",
    "response = requests.get(url)\n",
    "\n",
    "pt=[]\n",
    "au=[]\n",
    "pd1=[]\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "paper_title = soup.find_all('h2',class_=\"sc-1qrq3sd-1 gRGSUS sc-1nmom32-0 sc-1nmom32-1 btcbYu goSKRg\")\n",
    "\n",
    "\n",
    "authors = soup.find_all('span', class_=\"sc-1w3fpd7-0 dnCnAO\")\n",
    "\n",
    "\n",
    "pub_date = soup.find_all('span',class_=\"sc-1thf9ly-2 dvggWt\")\n",
    "\n",
    "\n",
    "#for header in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "#    headers_list.append(header.text.strip())\n",
    "#print(authors)\n",
    "#print(pub_date)\n",
    "\n",
    "for x in pub_date:\n",
    "   pd1.append(x.text.strip())\n",
    "\n",
    "for x in authors:\n",
    "   au.append(x.text.strip())\n",
    "\n",
    "\n",
    "for x in paper_title:\n",
    "    pt.append(x.text.strip())\n",
    "    \n",
    "#pd\n",
    "#au\n",
    "#pt\n",
    "\n",
    "data_list = [pt,au,pd1]\n",
    "#print(data_list)\n",
    "\n",
    "\n",
    "\n",
    "#columns = ['Paper Title', 'Authors', 'Published Date']\n",
    "\n",
    "\n",
    "df=pd.DataFrame(data_list)\n",
    "print(df)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38c87a7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f733d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c81f0614",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f049c61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    0\n",
      "0  Wikipedia\\n\\nThe Free Encyclopedia\n",
      "1            1,000,000+\\n\\n\\narticles\n",
      "2              100,000+\\n\\n\\narticles\n",
      "3               10,000+\\n\\n\\narticles\n",
      "4                1,000+\\n\\n\\narticles\n",
      "5                  100+\\n\\n\\narticles\n"
     ]
    }
   ],
   "source": [
    "#Write a python program to display all the header tags from wikipedia.org and make data frame\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = 'https://www.wikipedia.org/'\n",
    "response = requests.get(url)\n",
    "    \n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        \n",
    "headers_list = []\n",
    "        \n",
    "        # Find and extract header tags\n",
    "for header in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6']):\n",
    "    headers_list.append(header.text.strip())\n",
    "    \n",
    "\n",
    "df=pd.DataFrame(headers_list)\n",
    "print(df)\n",
    "\n",
    "\n",
    "    \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46cbe2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f231956c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5e0f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51ae0d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6e4a5ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  0   \\\n",
      "0  Russia mocks British efforts to support Ukrain...   \n",
      "1                                        an hour ago   \n",
      "\n",
      "                                                  1   \\\n",
      "0  Mega-rich renew call on global leaders at Davo...   \n",
      "1                                        an hour ago   \n",
      "\n",
      "                                                  2   \\\n",
      "0  'A trove of...opportunities': Strategists turn...   \n",
      "1                                         29 min ago   \n",
      "\n",
      "                                                  3   \\\n",
      "0  Tesla slashes car prices across Europe after s...   \n",
      "1                                         29 min ago   \n",
      "\n",
      "                                                  4   \\\n",
      "0  Dow falls for a third day as Treasury yields c...   \n",
      "1                                        5 hours ago   \n",
      "\n",
      "                                                  5   \\\n",
      "0  Jamie Dimon warns 'all these very powerful for...   \n",
      "1                                        5 hours ago   \n",
      "\n",
      "                                                  6   \\\n",
      "0  Winklevoss' crypto exchange Gemini gets nod to...   \n",
      "1                                         10 min ago   \n",
      "\n",
      "                                                  7   \\\n",
      "0  Kate, the Princess of Wales, will be hospitali...   \n",
      "1                                         10 min ago   \n",
      "\n",
      "                                  8   \\\n",
      "0  What is the World Economic Forum?   \n",
      "1                          6 min ago   \n",
      "\n",
      "                                                  9   ...           20  \\\n",
      "0  UN chief calls for global risk management of A...  ...         None   \n",
      "1                                          6 min ago  ...  3 hours ago   \n",
      "\n",
      "            21          22          23           24           25           26  \\\n",
      "0         None        None        None         None         None         None   \n",
      "1  3 hours ago  30 min ago  30 min ago  4 hours ago  4 hours ago  5 hours ago   \n",
      "\n",
      "            27           28           29  \n",
      "0         None         None         None  \n",
      "1  5 hours ago  6 hours ago  6 hours ago  \n",
      "\n",
      "[2 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "hl=[]\n",
    "ts=[]\n",
    "\n",
    "url='https://www.cnbc.com/world/?region=world'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "headlines = soup.find_all('div', class_=\"RiverHeadline-headline RiverHeadline-hasThumbnail\")\n",
    "for x in headlines:\n",
    "    hl.append(x.text.strip())\n",
    "    \n",
    "time_stamp = soup.find_all('span', class_=\"RiverByline-datePublished\")\n",
    "for x in time_stamp:\n",
    "    ts.append(x.text.strip())\n",
    "    \n",
    "data_list=[hl,ts]\n",
    "\n",
    "df=pd.DataFrame(data_list)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e8899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "abbe6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fbffa51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    0\n",
      "0   Shri Ram Nath Kovind\\n14th President of India\\...\n",
      "1   Shri Pranab Mukherjee\\n13th President of India...\n",
      "2   Smt Pratibha Devisingh Patil\\n12th President o...\n",
      "3   DR. A.P.J. Abdul Kalam\\n11th President of Indi...\n",
      "4   Shri K. R. Narayanan\\n10th President of India\\...\n",
      "5   Dr Shankar Dayal Sharma\\n9th  President of Ind...\n",
      "6   Shri R Venkataraman\\n8th President of India\\nR...\n",
      "7   Giani Zail Singh\\n7th President of India\\nGian...\n",
      "8   Shri Neelam Sanjiva Reddy\\n6th President of In...\n",
      "9   Dr. Fakhruddin Ali Ahmed\\n5th President of Ind...\n",
      "10  Shri Varahagiri Venkata Giri\\n4th President of...\n",
      "11  Dr. Zakir Husain\\n3rd President of India\\nZaki...\n",
      "12  Dr. Sarvepalli Radhakrishnan\\n2nd President of...\n",
      "13  Dr. Rajendra Prasad\\n1st President of India\\nR...\n",
      "14  Shri Ram Nath Kovind\\nFormer President of Indi...\n",
      "15  Shri Pranab Mukherjee\\nFormer President of Ind...\n",
      "16  Smt Pratibha Devisingh Patil\\nFormer President...\n",
      "17  DR. A.P.J. Abdul Kalam\\nFormer President of In...\n",
      "18  Shri K. R. Narayanan\\nFormer President of Indi...\n",
      "19  Dr Shankar Dayal Sharma\\nFormer President of I...\n",
      "20  Shri R Venkataraman\\nFormer President of India...\n",
      "21  Giani Zail Singh\\nFormer President of India\\n ...\n",
      "22  Shri Neelam Sanjiva Reddy\\nFormer President of...\n",
      "23  Dr. Fakhruddin Ali Ahmed\\nFormer President of ...\n",
      "24  Shri Varahagiri Venkata Giri\\nFormer President...\n",
      "25  Dr. Zakir Husain\\nFormer President of India\\n ...\n",
      "26  Dr. Sarvepalli Radhakrishnan\\nFormer President...\n",
      "27  Dr. Rajendra Prasad\\nFormer President of India...\n"
     ]
    }
   ],
   "source": [
    "#Write a python program to display list of respected former presidents of India(i.e. Name , Term ofoffice) \n",
    "#from https://presidentofindia.nic.in/former-presidents.htm and make data frame. \n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url='https://presidentofindia.nic.in/'\n",
    "response = requests.get(url)\n",
    "president_list=[]\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "pres_element=soup.find_all('div',class_='wgl-services_content-wrap')\n",
    " \n",
    "x1=[]\n",
    "for x in pres_element:\n",
    "    x1.append(x.text.strip())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame(x1)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ed2db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a234ffdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a94a51d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e43495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape mentioned details from dineout.co.in and make data frame- \n",
    "#REstaurant name\n",
    "#Cuisine \n",
    "#Location \n",
    "#Ratings \n",
    "#Image URL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "20d5e2d7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 21\u001b[0m\n\u001b[0;32m     14\u001b[0m rating\u001b[38;5;241m=\u001b[39msoup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m'\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkGUdK _1oTbl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m Location\u001b[38;5;241m=\u001b[39msoup\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mp\u001b[39m\u001b[38;5;124m'\u001b[39m,class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_1jbOb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m rest_name:\n\u001b[0;32m     22\u001b[0m    rn\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip())\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m rating:\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url='https://www.dineout.co.in/hyderabad'\n",
    "response = requests.get(url)\n",
    "rn=[]\n",
    "rt=[]\n",
    "loc=[]\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "rest_name=soup.find('h4',class_=\"_1jbOb\")\n",
    "\n",
    "rating=soup.find('div', class_=\"kGUdK _1oTbl\")\n",
    "\n",
    "Location=soup.find('p',class_=\"_1jbOb\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for x in rest_name:\n",
    "   rn.append(x.text.strip())\n",
    "\n",
    "for x in rating:\n",
    "   rt.append(x.text.strip())\n",
    "\n",
    "\n",
    "for x in Location:\n",
    "    loc.append(x.text.strip())\n",
    "    \n",
    "data_list = [rn,rt,loc]\n",
    "#print(data_list)\n",
    "\n",
    "\n",
    "\n",
    "columns = [Restaurant_name,Rating,Location]\n",
    "\n",
    "\n",
    "df=pd.DataFrame(data_list)\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc857899",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
