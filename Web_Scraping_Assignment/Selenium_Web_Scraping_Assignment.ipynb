{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff49b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, \n",
    "#Term of office, Remarks) from https://www.jagranjosh.com/. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c32973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver=webdriver.Edge()\n",
    "\n",
    "url=\"https://www.jagranjosh.com/\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "GK_element=driver.find_element(By.XPATH,\"//a[@href='https://www.jagranjosh.com/general-knowledge']\")\n",
    "GK_element.click()\n",
    "\n",
    "Explore_element=driver.find_element(By.XPATH,\"//a[@href='https://www.jagranjosh.com/general-knowledge-india-an-overview-1291979784-1']\")\n",
    "Explore_element.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106b75ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You \n",
    "#have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 \n",
    "#jobs data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92ec9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "driver = webdriver.Edge()\n",
    "\n",
    "url = 'https://www.shine.com'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "\n",
    "#<div id=\"select_container_id_q\" class=\"position-relative\"><input type=\"text\" id=\"id_q\" name=\"id_q\" autocomplete=\"off\" placeholder=\" \" class=\"form-control  \" value=\"\"><label class=\"input-label \" for=\"id_q\">Job title, skills</label></div>\n",
    "#search_job_title=WebDriverWait(driver,20).until(EC.visibility_of_element_located((By.NAME,\"id_q\")))\n",
    "                                                            \n",
    "search_job_title = driver.find_element(By.XPATH,'//div[@id=\"select_container_id_q\"]/input=[@type=\"text\"]')\n",
    "\n",
    "#search_job_title = driver.find_element(By.ID,\"id_q\")\n",
    "\n",
    "\n",
    "search_location = driver.find_element(By.XPATH,'//div[@id=\"select_container_id_loc\"]/input[@id=\"id_loc\"]')\n",
    "\n",
    "\n",
    "search_job_title.send_keys('Data Analyst')\n",
    "search_location.send_keys('Bangalore')\n",
    "\n",
    "#<button type=\"submit\" class=\" btn btn-secondary undefined\">Search jobs</button>\n",
    "\n",
    "#search_button = driver.find_element(\"xpath\",'//button[@class='btn btn-secondary undefined']')\n",
    "#search_button.click()\n",
    "\n",
    "# Wait for the search results to load\n",
    "\n",
    "#results_xpath = '//div[@class=\"job-listing\"]/div[@class=\"job-title\"]'\n",
    "\n",
    "#WebDriverWait(driver, 10).until(\n",
    "#    EC.presence_of_element_located((By.XPATH, results_xpath))\n",
    "\n",
    "\n",
    "# Scrape data for the first 10 jobs\n",
    "#jobs = driver.find_elements(By.XPATH, results_xpath)[:10]\n",
    "\n",
    "#for job in jobs:\n",
    "#    title = job.find_element(By.CLASS_NAME, 'job-title').text\n",
    "#    location = job.find_element(By.CLASS_NAME, 'job-location').text\n",
    "#    company_name = job.find_element(By.CLASS_NAME, 'company-name').text\n",
    "#    experience_required = job.find_element(By.CLASS_NAME, 'experience').text\n",
    "\n",
    "#    print(f\"Job Title: {title}\\nLocation: {location}\\nCompany Name: {company_name}\\nExperience Required: {experience_required}\\n---\")\n",
    "\n",
    "# Clean up\n",
    "#driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63441421",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write a python program to scrape data for Top 1000 Quotes of All Time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27e9cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver=webdriver.Edge()\n",
    "\n",
    "url=\"https://www.azquotes.com/\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "quote=driver.find_element(By.XPATH,\"//a[@href='/top_quotes.html']\")\n",
    "quote.click()\n",
    "\n",
    "quotes=driver.find_elements(By.XPATH,\"//a[@class='title']\")\n",
    "authors=driver.find_elements(By.XPATH,\"//div[@class='author']\")\n",
    "type_quote=driver.find_elements(By.XPATH,\"//div[@class='tags']\")\n",
    "\n",
    "quotes_list=[]\n",
    "for q1 in range(len(quotes)):\n",
    "    quotes_list.append(quotes[q1].text)\n",
    "\n",
    "\n",
    "authors_list=[]\n",
    "for a1 in range(len(authors)):\n",
    "    authors_list.append(authors[a1].text)\n",
    "\n",
    "type_quote_list=[]\n",
    "for a1 in range(len(type_quote)):\n",
    "    type_quote_list.append(type_quote[a1].text)\n",
    "\n",
    "\n",
    "data_tuples = list(zip(quotes_list[1:],authors_list[1:],type_quote_list[1:])) \n",
    "dataFrame = pd.DataFrame(data_tuples, columns=['Quote','Author','Type of Quote'])\n",
    "print(dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f967fd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then \n",
    "#set CPU Type filter to “Intel Core i7” as shown in the below image: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9e6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "driver=webdriver.Edge()\n",
    "driver.maximize_window()\n",
    "\n",
    "url=\"https://www.amazon.com\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "\n",
    "search_box=driver.find_element(By.ID,'twotabsearchtextbox')\n",
    "search_box.send_keys(\"Laptop\")\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "\n",
    " \n",
    "check_box=WebDriverWait(driver,40).until(EC.element_to_be_clickable((By.XPATH,\"//div[@class='a-checkbox a-checkbox-fancy s-navigation-checkbox aok-float-left']/label/input[@type='checkbox']\")))\n",
    "check_box.click()\n",
    "\n",
    "#<div class=\"a-checkbox a-checkbox-fancy s-navigation-checkbox aok-float-left\"><label><input type=\"checkbox\" name=\"\" value=\"\"><i class=\"a-icon a-icon-checkbox\"></i><span class=\"a-label a-checkbox-label\"></span></label></div>\n",
    "\n",
    "#After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop: \n",
    "#1. Title \n",
    "#2. Ratings \n",
    "#3. Price \n",
    "\n",
    "\n",
    "#Title=driver.find_elements(By.XPATH,\"//form[@id='nav-search-bar-form'/a[@class='a-link-normal s-underline-text s-underline-link-text s-link-style a-text-normal']\").text\n",
    "\n",
    "\n",
    "#Ratings=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\").text\n",
    "\n",
    "\n",
    "#price=driver.find_elements(By.XPATH,\"//span[@class='a-price']\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b87fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the \n",
    "#search field. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e7c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import pandas as pd\n",
    "\n",
    "driver=webdriver.Edge()\n",
    "\n",
    "url=\"https://www.flipkart.com/\"\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "search_box=driver.find_element(By.XPATH,\"//div[@class='_2SmNnR']/input[@name='q']\")\n",
    "search_box.send_keys(\"sunglasses\")\n",
    "search_box.send_keys(Keys.RETURN)\n",
    "\n",
    "Brand=driver.find_elements(By.XPATH,\"//div[@class='_2WkVRV']\")\n",
    "prod_desc=driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "\n",
    "price=driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "\n",
    "\n",
    "Brand_list=[]\n",
    "for q1 in range(len(Brand)):\n",
    "    Brand_list.append(Brand[q1].text)\n",
    "\n",
    "\n",
    "prod_desc_list=[]\n",
    "for a1 in range(len(prod_desc)):\n",
    "    prod_desc_list.append(prod_desc[a1].text)\n",
    "\n",
    "price_list=[]\n",
    "for a1 in range(len(price)):\n",
    "    price_list.append(price[a1].text)\n",
    "\n",
    "\n",
    "data_tuples = list(zip(Brand_list[1:],prod_desc_list[1:],price_list[1:])) \n",
    "dataFrame = pd.DataFrame(data_tuples, columns=['Brand','Product Description','Price'])\n",
    "print(dataFrame)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d62597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. \n",
    "#Car name and Price) from https://www.motor1.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e59c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "   \n",
    "   \n",
    "driver = webdriver.Edge()\n",
    "    \n",
    "    \n",
    "url = 'https://www.motor1.com/'\n",
    "driver.get(url)\n",
    "    \n",
    "   \n",
    "    \n",
    "# Wait for the search input to be visible\\n\",\n",
    "search_input = driver.find_element(By.XPATH, '//input[@id=\"m1-search-panel-input m1-search-form-text\"]')\n",
    "    \n",
    "    # Search for the term '50 most expensive cars\n",
    "                                                   \n",
    "search_input.send_keys('50 most expensive cars')\n",
    "\n",
    "#Find and click on the search button\\n\",\n",
    "#search_button =driver.find_element(By.XPATH, '//button[@class=\\\"m1-search-form-button-animate icon-search-svg m1-mobile-search\\\"]'))\n",
    "\n",
    "#search_button.click()\n",
    "    \n",
    "# Wait for the search results to load\\n\n",
    "    #car_elements = WebDriverWait(driver, 10).until(\\n\",\n",
    "   \n",
    "    # Extract car names and prices\\n\",\n",
    "\"\"\"    for car_element in car_elements[:50]:\n",
    "        car_name = car_element.find_element(By.CLASS_NAME, 'title').text\n",
    "       car_price = car_element.find_element(By.CLASS_NAME, 'price').text\n",
    "        print(f\\\"{car_name} - {car_price}\"\"\"\n",
    "    \n",
    "    # Clean up\\n\",\n",
    "    #driver.quit()\\n\",\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
